<h1 align="center">Web Scraping de publica√ß√µes do DJE</h1>

<br/>

<p align="center">
<a href="#-sobre">Sobre</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
<a href="#-tecnologias">Tecnologias</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
<a href="#-funcionalidades-principais">Funcionalidades principais</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
<a href="#-implementa√ß√µes-para-melhoria-de-resultados">Implementa√ß√µes para melhoria de resultados</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
<a href="#%EF%B8%8F-instala√ß√£o-e-execu√ß√£o">Instala√ß√£o e execu√ß√£o</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
<a href="#-outros-links">Outros links</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
<a href="#-pontos-de-melhoria">Pontos de melhoria</a>

</p>

## ‚ùî Sobre

O projeto foi idealizado para realizar a busca das publica√ß√µes do [DJE](https://dje.tjsp.jus.br/cdje/index.do) do "Caderno 3 - Judicial - 1¬™ Inst√¢ncia - Capital - Parte I" entre as datas de 01/10/24 e 29/11/24 e salvar no banco de dados principal do projeto
<br/>


## üîß Tecnologias

Esse projeto foi desenvolvido com as seguintes tecnologias:

- [Python](https://www.python.org/)
- [Selenium](https://selenium-python.readthedocs.io/)
- [Python dotenv](https://pypi.org/project/python-dotenv/)
- [Requests](https://requests.readthedocs.io/en/latest/)

## üß† Funcionalidades principais

  - Busca de publica√ß√µes por intervalo de datas(hardcode no momento para n√£o ferir os requisitos do teste)
  - Envio das publica√ß√µes para armazenamento via API
    
## üöÄ Implementa√ß√µes para melhoria de resultados

  - Utiliza√ß√£o do webdriver do Selenium ao inv√©s do BeautifulSoup para lidar com certifica√ß√µes do DJE e ter mais controle sobre as p√°ginas
  - Caso a publica√ß√£o n√£o esteja completa(parte dos dados estar no pdf anterior ou posterior) ele navega para a p√°gina correta e une as informa√ß√µes
  - Envio dos posts por dia, faz a coleta daquele dia e ao final envia para a API, reduzindo os riscos de corrompimento de dados
  - Fechamento do navegador ao fim da coleta de cada dia para que ao iniciar o scraping do pr√≥ximo dia a certifica√ß√£o seja renovada
  - Em caso de impedimento do envio para a API salva o JSON que seria enviado nos arquivos do projeto
  

## ‚öôÔ∏è Instala√ß√£o e execu√ß√£o
  <p>Garanta que voce tem o Python instalado e coloque o arquivo execut√°vel do [webdriver Firefox](https://github.com/mozilla/geckodriver/releases), de acordo com seu sistema operacional, na raiz do projeto</p>

  ```
  git clone https://github.com/IagoJDiniz/dje-scraping.git
  cd dje-scraping

  pip install -r requirements.txt
  ```
  <p>Crie um arquivo .env com as seguintes vari√°veis:</p>

  ```
API_URL=http://localhost:3333/register-posts
SCRAPER_API_KEY=mesma_key_utilizada_no_backend
```

  
<p>Por fim execute:</p>

```
python src/main.py
```
<strong>O comando "python" pode ser "python3" caso esteja em uma distribui√ß√£o linux(Mas isso voc√™ j√° deve saber)</strong>
<br/>
  - A busca, extra√ß√£o e salvamento levam em torno de 4h(s√£o mais de 1300 publica√ß√µes) e est√£o sendo executadas diariamente via githubActions nesse reposit√≥rio
  - Caso tenha interesse em ver o navegador rodando basta "comentar" a linha contendo "--headless" no src/scraper/browser.py
<br/>  

  
  
  

## üìÑ Outros links

[API](https://github.com/IagoJDiniz/JusCashCase/)
<br/>
[Front-end](https://github.com/IagoJDiniz/juscash-front/)
<br/>


## üìà Pontos de melhoria
  - Fazer uma tratativa melhor de identifica√ß√£o de erros humanos, como publica√ß√µes que duplicaram os advogados ou cujo padr√£o de escrita dos autores foi ferido(vide processo 0029091-39.2024.8.26.0053 em que um dos advogados aparece mais de 08 vezes)
  - Aprimorar as limita√ß√µes de tempo at√© a execu√ß√£o de alguma fun√ß√£o, infelizmente testei m√∫ltiplas alternativas mas o "time.sleep()" foi o √∫nico que conseguiu garantir a execu√ß√£o sem falhas no site do governo
  - Documentar as fun√ß√µes do c√≥digo, alguns coment√°rios foram utilizados e a estrutura de cada arquivo est√° bem enxuta, por√©m isso n√£o tem o mesmo valor de uma documenta√ß√£o completa
